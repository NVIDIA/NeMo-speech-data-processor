# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import collections
import re
from typing import Dict, List

from sdp.logging import logger
from sdp.processors.base_processor import DataEntry
from sdp.processors.modify_manifest.modify_manifest import ModifyManifestTextProcessor
from sdp.utils.edit_spaces import add_start_end_spaces
from sdp.utils.get_diff import get_diff_with_subs_grouped


class InsIfASRInsertion(ModifyManifestTextProcessor):
    """
    Class for processor that adds a substring to data[self.text_key] if it is
    present at that location in data[self.pred_text_key].
    It is useful if words are systematically missing from ground truth
    transcriptions.

    Args:
        insert_words: list of strings that will be inserted into data[self.text_key] if
            there is an insertion (containing only that string) in data[self.pred_text_key].
            Note: because data_to_data looks for an exact match in the insertion,
            we recommend including variations with different spaces in 'insert_words',
            e.g. [' nemo', 'nemo ', ' nemo '].
    """

    def __init__(
        self, insert_words: List[str], **kwargs,
    ):
        super().__init__(**kwargs)
        self.insert_words = insert_words

    def _process_dataset_entry(self, data_entry) -> List:
        insert_word_counter = collections.defaultdict(int)
        for insert_word in self.insert_words:
            if not insert_word in data_entry[self.pred_text_key]:
                break
            orig_words, pred_words = data_entry[self.text_key], data_entry[self.pred_text_key]
            diff = get_diff_with_subs_grouped(orig_words, pred_words)

            if len(diff) > 0:  # ie if there are differences between text and pred_text

                new_sent = ""

                for diff_entry in diff:
                    if diff_entry[0] == 0:  # no change
                        new_sent += diff_entry[1]

                    elif diff_entry[0] == -1:  # deletion in original string
                        new_sent += diff_entry[1]

                    elif diff_entry[0] == 1:  # insertion in original string
                        if diff_entry[1] == insert_word:
                            new_sent += insert_word
                            insert_word_counter[insert_word] += 1

                    elif isinstance(diff_entry, tuple):  # i.e. diff is a substitution
                        new_sent += diff_entry[0][1]
                    else:
                        raise ValueError(f"unexpected item in diff_entry: {diff_entry}")

                new_sent = " ".join(new_sent.split())  # remove any extra spaces
                data_entry[self.text_key] = new_sent

        return [DataEntry(data=data_entry, metrics=insert_word_counter)]

    def finalize(self, metrics):
        total_counter = collections.defaultdict(int)
        for counter in metrics:
            for word, count in counter.items():
                total_counter[word] += count
        logger.info("Num of words that were inserted")
        for word, count in total_counter.items():
            logger.info(f"{word} {count}")
        super().finalize(metrics)


class SubIfASRSubstitution(ModifyManifestTextProcessor):
    """
    Class for processor that converts a substring in data[self.text_key] to a
    substring in data[self.pred_text_key] if both are located in the same place
    (ie are part of a 'substitution' operation) and if the substrings
    correspond to key-value pairs in 'sub_words'.
    This is useful if words are systematically incorrect in ground truth
    transcriptions.

    Args:
        sub_words: dictionary where a key is a string that might be in data[self.text_key]
            and the value is the string that might be in data[self.pred_text_key]. If both
            are located in the same place (ie are part of a 'substitution' operation)
            then the key string will be converted to the value string in data[self.text_key].

            .. note::
                data_to_data looks for exact string matches of substitutions, so
                you may need to be careful with spaces in 'sub_words', e.g.
                recommended to do sub_words = {"nmo ": "nemo "} instead of
                sub_words = {"nmo" : "nemo"}
    """

    def __init__(
        self, sub_words: Dict, **kwargs,
    ):
        super().__init__(**kwargs)
        self.sub_words = sub_words

    def _process_dataset_entry(self, data_entry) -> List:
        sub_word_counter = collections.defaultdict(int)
        for original_word, new_word in self.sub_words.items():
            if not original_word in data_entry[self.text_key]:
                break
            orig_words, pred_words = data_entry[self.text_key], data_entry[self.pred_text_key]
            diff = get_diff_with_subs_grouped(orig_words, pred_words)

            if len(diff) > 0:  # ie if there are differences between text and pred_text

                new_sent = ""

                for diff_entry in diff:
                    if diff_entry[0] == 0:  # no change
                        new_sent += diff_entry[1]

                    elif diff_entry[0] == -1:  # deletion in original string
                        new_sent += diff_entry[1]

                    elif diff_entry[0] == 1:  # insertion in original string
                        # don't make changes
                        pass

                    elif isinstance(diff_entry, tuple):  # substitution
                        if diff_entry[0][1] == original_word and diff_entry[1][1] == new_word:
                            # ie. substitution is one we want to use to change the original text
                            new_sent += new_word
                            sub_word_counter[original_word] += 1

                        else:
                            # ie. substitution is one we want to ignore
                            new_sent += diff_entry[0][1]
                    else:
                        raise ValueError(f"unexpected item in diff_entry: {diff_entry}")

                new_sent = add_start_end_spaces(new_sent)
                data_entry[self.text_key] = new_sent

        return [DataEntry(data=data_entry, metrics=sub_word_counter)]

    def finalize(self, metrics):
        total_counter = collections.defaultdict(int)
        for counter in metrics:
            for word, count in counter.items():
                total_counter[word] += count
        logger.info("Num of words that were substituted")
        for word, count in total_counter.items():
            logger.info(f"{word} {count}")
        super().finalize(metrics)


class SubMakeLowercase(ModifyManifestTextProcessor):
    """
    Class to convert data[self.text_key] to lowercase by calling '.lower()' on it.
    """

    def __init__(
        self, **kwargs,
    ):
        super().__init__(**kwargs)

    def _process_dataset_entry(self, data_entry) -> List:
        data_entry[self.text_key] = data_entry[self.text_key].lower()
        return [DataEntry(data=data_entry)]

    def finalize(self, metrics):
        logger.info("Made all letters lowercase")
        super().finalize(metrics)


class SubRegex(ModifyManifestTextProcessor):
    """
    Class for processor that converts a regex match to a string, as defined
    by key-value pairs in regex_to_sub.

    Args:
        regex_params_list: list of dicts. Each dict must contain a 'pattern' and 'repl' key,
            and optionally a 'count' key (by default, 'count' will be 0).
            This processor will go through the list in order, and apply a re.sub operation on
            the input text in data_entry[self.text_key], feeding in the specified 'pattern', 'repl'
            and 'count' parameters to re.sub.
    """

    def __init__(
        self, regex_params_list: List[Dict], **kwargs,
    ):
        super().__init__(**kwargs)
        self.regex_params_list = regex_params_list

        # verify all dicts in regex_params_list have "pattern" and "repl" keys
        for regex_params_dict in self.regex_params_list:
            if not "pattern" in regex_params_dict.keys():
                raise ValueError(
                    f"Need to have key 'pattern' in all entries of `regex_params_list`: {self.regex_params_list}"
                )
            if not "repl" in regex_params_dict.keys():
                raise ValueError(
                    f"Need to have key 'repl' in all entries of `regex_params_list`: {self.regex_params_list}"
                )

    def _process_dataset_entry(self, data_entry) -> List:
        replace_word_counter = collections.defaultdict(int)

        text_in = data_entry[self.text_key]

        for regex_params in self.regex_params_list:

            text_out = re.sub(
                pattern=regex_params["pattern"],
                repl=regex_params["repl"],
                string=text_in,
                # note: this count param is the maximum number of pattern occurrences to be replaced.
                count=regex_params.get("count", 0),
            )

            if text_in != text_out:
                replace_word_counter[regex_params["pattern"]] += 1
            text_in = text_out

        data_entry[self.text_key] = text_out

        return [DataEntry(data=data_entry, metrics=replace_word_counter)]

    def finalize(self, metrics):
        total_counter = collections.defaultdict(int)
        for counter in metrics:
            for word, count in counter.items():
                total_counter[word] += count
        logger.info("Number of utterances which applied substitutions for the following patterns:")
        total_counter_sorted = dict(sorted(total_counter.items(), key=lambda x: x[1], reverse=True))
        for word, count in total_counter_sorted.items():
            logger.info(f"{word} {count}")
        super().finalize(metrics)
